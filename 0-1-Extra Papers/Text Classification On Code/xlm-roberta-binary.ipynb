{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1382412,"sourceType":"datasetVersion","datasetId":806606},{"sourceId":6442538,"sourceType":"datasetVersion","datasetId":3718466},{"sourceId":7437175,"sourceType":"datasetVersion","datasetId":4328491}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification","metadata":{"id":"2e0f75c3","outputId":"1968999e-09e5-4f8d-fb47-377c1b235879","papermill":{"duration":13.349991,"end_time":"2023-07-25T16:06:48.929213","exception":false,"start_time":"2023-07-25T16:06:35.579222","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T21:46:18.471885Z","iopub.execute_input":"2024-01-20T21:46:18.472247Z","iopub.status.idle":"2024-01-20T21:46:24.214938Z","shell.execute_reply.started":"2024-01-20T21:46:18.472216Z","shell.execute_reply":"2024-01-20T21:46:24.214034Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"model_name = 'xlm-roberta-base'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\n\n# Define device (CPU or GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"id":"4913d932","outputId":"5eb3dd9b-5b04-4803-ae2a-b601b8da7ba0","papermill":{"duration":4.173444,"end_time":"2023-07-25T16:06:53.106774","exception":false,"start_time":"2023-07-25T16:06:48.933330","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T21:46:24.216547Z","iopub.execute_input":"2024-01-20T21:46:24.216972Z","iopub.status.idle":"2024-01-20T21:46:45.127158Z","shell.execute_reply.started":"2024-01-20T21:46:24.216943Z","shell.execute_reply":"2024-01-20T21:46:45.126233Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85e649a505d24f349f0036b761db6be8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8f12d605adc40e2a359ad2c8876872a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a8df25fe0a54f45a42165926304cdd6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f1fa3b36cfa427cb6d8c894b7e3e8c6"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ntrain_url = '/kaggle/input/revised-corrector-dataset/train_corr.csv'\ntest_url = '/kaggle/input/revised-corrector-dataset/test_corr.csv'\ndf_train = pd.read_csv(train_url)\ndf_test = pd.read_csv(test_url)\nstop_words_df = pd.read_excel('/kaggle/input/bangla-stopwords/stopwords_bangla.xlsx',index_col=False)","metadata":{"id":"b0560ae3","papermill":{"duration":0.132745,"end_time":"2023-07-25T16:06:53.244675","exception":false,"start_time":"2023-07-25T16:06:53.111930","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T21:46:45.128303Z","iopub.execute_input":"2024-01-20T21:46:45.128586Z","iopub.status.idle":"2024-01-20T21:46:45.966942Z","shell.execute_reply.started":"2024-01-20T21:46:45.128561Z","shell.execute_reply":"2024-01-20T21:46:45.966101Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"STOPWORDS = set([word.strip() for word in stop_words_df['words']])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T21:46:45.969510Z","iopub.execute_input":"2024-01-20T21:46:45.970501Z","iopub.status.idle":"2024-01-20T21:46:45.980093Z","shell.execute_reply.started":"2024-01-20T21:46:45.970463Z","shell.execute_reply":"2024-01-20T21:46:45.979110Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import re\ndef preprocess(x):\n    html_pattern = re.compile('<.*?>')\n    x = html_pattern.sub(r'', x)\n    x = \" \".join([word for word in str(x).split() if word not in STOPWORDS])\n    return x\ndf_train['Comment'] = df_train['Comment'].apply(lambda x: preprocess(x))\ndf_test['Comment'] = df_test['Comment'].apply(lambda x:preprocess(x))\ndf_train[\"Error\"] = df_train[\"Error\"].astype(int)\ndf_test[\"Error\"] = df_test[\"Error\"].astype(int)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T21:46:45.981236Z","iopub.execute_input":"2024-01-20T21:46:45.981581Z","iopub.status.idle":"2024-01-20T21:46:46.141716Z","shell.execute_reply.started":"2024-01-20T21:46:45.981549Z","shell.execute_reply":"2024-01-20T21:46:46.140859Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_no = 5\n\n# Prepare the training data\ntrain_texts = df_train['Comment'].tolist()\ntrain_labels = df_train['Error'].tolist()\n\ntest_texts = df_test['Comment'].tolist()\ntest_labels = df_test['Error'].tolist()","metadata":{"id":"6b9dc3e4","papermill":{"duration":0.018204,"end_time":"2023-07-25T16:06:53.268005","exception":false,"start_time":"2023-07-25T16:06:53.249801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T21:46:46.142795Z","iopub.execute_input":"2024-01-20T21:46:46.143085Z","iopub.status.idle":"2024-01-20T21:46:46.151145Z","shell.execute_reply.started":"2024-01-20T21:46:46.143061Z","shell.execute_reply":"2024-01-20T21:46:46.150288Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the training texts\ntrain_encodings = tokenizer(train_texts, truncation=True, max_length=128,\n        padding='max_length', return_tensors = 'pt')\n\n# Convert the labels to tensors\ntrain_labels = torch.tensor(train_labels)\n\n\n# Create a PyTorch dataset\ntrain_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'],\n                                               train_encodings['attention_mask'],\n                                               train_labels)\n\n# Create a data loader\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n\nmodel = model.to(device)","metadata":{"id":"c68abf8e","outputId":"fc006e00-bc36-49f7-9041-3cc6a300504b","papermill":{"duration":11.003131,"end_time":"2023-07-25T16:07:04.276102","exception":false,"start_time":"2023-07-25T16:06:53.272971","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T21:46:46.152508Z","iopub.execute_input":"2024-01-20T21:46:46.152794Z","iopub.status.idle":"2024-01-20T21:46:50.204166Z","shell.execute_reply.started":"2024-01-20T21:46:46.152770Z","shell.execute_reply":"2024-01-20T21:46:50.203319Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nfrom sklearn.metrics import accuracy_score\n\n# Set the model to training mode\nmodel.train()\n\n# Define the optimizer and loss function\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\nloss_fn = torch.nn.CrossEntropyLoss()\n\nlosses = []\naccuracies = []  # To store accuracy per epoch\nnum_epochs = 5\n# Training loop\nfor epoch in tqdm(range(num_epochs)):  # Number of training epochs\n    running_loss = 0.0\n    predicted_labels = []  # To store predicted labels for accuracy calculation\n    true_labels = []  # To store true labels for accuracy calculation\n\n    for batch in tqdm(train_loader):\n        input_ids = batch[0].to(device)\n        attention_mask = batch[1].to(device)\n        labels = batch[2].to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        logits = outputs.logits\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        # Convert logits to predicted labels\n        _, predicted = torch.max(logits, dim=1)\n        predicted_labels.extend(predicted.cpu().tolist())\n        true_labels.extend(labels.cpu().tolist())\n\n    epoch_loss = running_loss / len(train_loader)\n    losses.append(epoch_loss)\n\n    # Calculate and store accuracy\n    accuracy = accuracy_score(true_labels, predicted_labels)\n    accuracies.append(accuracy)\n\n    print(f'Epoch {epoch + 1}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {accuracy:.4f}')\n\n# Save the model\ntorch.save(model.state_dict(), 'model.pth')","metadata":{"id":"eedb3a9c","outputId":"81f0d82e-5d90-4271-e5cf-71638bf8bc98","papermill":{"duration":668.41198,"end_time":"2023-07-25T16:18:12.693572","exception":false,"start_time":"2023-07-25T16:07:04.281592","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T21:46:50.205341Z","iopub.execute_input":"2024-01-20T21:46:50.205640Z","iopub.status.idle":"2024-01-20T22:30:39.700359Z","shell.execute_reply.started":"2024-01-20T21:46:50.205615Z","shell.execute_reply":"2024-01-20T22:30:39.699471Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fe764ca76924e10b5fbb56478162bb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1256 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de524c610e5a4a0d8dd3d5f46295ffc3"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/5 - Loss: 0.5321 - Accuracy: 0.7360\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1256 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cd1056c6f364b28bd8b607494bf5027"}},"metadata":{}},{"name":"stdout","text":"Epoch 2/5 - Loss: 0.4219 - Accuracy: 0.8125\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1256 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe2240dea8564492bb991d3b2bc2e14e"}},"metadata":{}},{"name":"stdout","text":"Epoch 3/5 - Loss: 0.3694 - Accuracy: 0.8446\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1256 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"486f5ba8cc504eaf8e442ead0d85de73"}},"metadata":{}},{"name":"stdout","text":"Epoch 4/5 - Loss: 0.3452 - Accuracy: 0.8523\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1256 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b91d0fb8b149bcbd9c1cc50c9c6c03"}},"metadata":{}},{"name":"stdout","text":"Epoch 5/5 - Loss: 0.2924 - Accuracy: 0.8812\n","output_type":"stream"}]},{"cell_type":"code","source":"#dgfdgdfgdgffdgdfd1212jhkhk","metadata":{"papermill":{"duration":0.014424,"end_time":"2023-07-25T16:18:12.713695","exception":false,"start_time":"2023-07-25T16:18:12.699271","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:30:39.701762Z","iopub.execute_input":"2024-01-20T22:30:39.702137Z","iopub.status.idle":"2024-01-20T22:30:39.706527Z","shell.execute_reply.started":"2024-01-20T22:30:39.702103Z","shell.execute_reply":"2024-01-20T22:30:39.705660Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n\ndef predict_labels(text):\n    train_encodings = tokenizer(text, truncation=True, max_length=128,\n        padding='max_length', return_tensors = 'pt')\n    input_ids = train_encodings['input_ids'].to(device)\n    attention_mask = train_encodings['attention_mask'].to(device)\n\n    # Set the model to evaluation mode\n    model.eval()\n\n    # Disable gradient calculation\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n\n    logits = outputs.logits\n    probabilities = torch.softmax(logits, dim=1)\n    predicted_class = torch.argmax(probabilities, dim=1)\n    \n\n    return predicted_class.item(), probabilities[:,1].item()","metadata":{"id":"1243273c","papermill":{"duration":0.69644,"end_time":"2023-07-25T16:18:13.415572","exception":false,"start_time":"2023-07-25T16:18:12.719132","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:30:39.709516Z","iopub.execute_input":"2024-01-20T22:30:39.709802Z","iopub.status.idle":"2024-01-20T22:30:39.722168Z","shell.execute_reply.started":"2024-01-20T22:30:39.709777Z","shell.execute_reply":"2024-01-20T22:30:39.721291Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"predicted_labels = []\npredicted_probs = []\nfor text in tqdm(test_texts):\n    predicted_label, prob = predict_labels(text)\n    predicted_labels.append(predicted_label)\n    predicted_probs.append(prob)\n\n# Calculate accuracy and F1 score\naccuracy = accuracy_score(test_labels, predicted_labels)\n# f1 = f1_score(test_labels, predicted_labels)\n# roc_auc = roc_auc_score(test_labels, predicted_probs)\n\nprint('Accuracy:', accuracy)\n# print('F1 Score:', f1)'xlm-roberta-base'\n# print('ROC-AUC:', roc_auc)","metadata":{"id":"d57fe764","outputId":"d7e9495a-7096-413f-cc6e-0f3e69cdc327","papermill":{"duration":56.127329,"end_time":"2023-07-25T16:19:09.548653","exception":false,"start_time":"2023-07-25T16:18:13.421324","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:30:39.723384Z","iopub.execute_input":"2024-01-20T22:30:39.723650Z","iopub.status.idle":"2024-01-20T22:31:56.099340Z","shell.execute_reply.started":"2024-01-20T22:30:39.723627Z","shell.execute_reply":"2024-01-20T22:31:56.098407Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5022 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8f7924a32684a0791879a114b069e52"}},"metadata":{}},{"name":"stdout","text":"Accuracy: 0.7913181999203505\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Accuracy:', accuracy)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:31:56.100598Z","iopub.execute_input":"2024-01-20T22:31:56.100882Z","iopub.status.idle":"2024-01-20T22:31:56.105393Z","shell.execute_reply.started":"2024-01-20T22:31:56.100850Z","shell.execute_reply":"2024-01-20T22:31:56.104440Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Accuracy: 0.7913181999203505\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, classification_report\n\nprint('\\nThe Classification Report is as follows\\n')\nprint(classification_report(test_labels, predicted_labels, digits = 4))","metadata":{"papermill":{"duration":0.031899,"end_time":"2023-07-25T16:19:09.586107","exception":false,"start_time":"2023-07-25T16:19:09.554208","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-20T22:31:56.106488Z","iopub.execute_input":"2024-01-20T22:31:56.106729Z","iopub.status.idle":"2024-01-20T22:31:56.137925Z","shell.execute_reply.started":"2024-01-20T22:31:56.106708Z","shell.execute_reply":"2024-01-20T22:31:56.137002Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\nThe Classification Report is as follows\n\n              precision    recall  f1-score   support\n\n           0     0.7041    0.7785    0.7394      1910\n           1     0.8546    0.7992    0.8260      3112\n\n    accuracy                         0.7913      5022\n   macro avg     0.7794    0.7888    0.7827      5022\nweighted avg     0.7974    0.7913    0.7931      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}